<center>

# <br>

![alt text](image.png)
<br>
# <font face="黑体">《程序设计实验》需求分析文档
<br>

![alt text](image-1.png)
<br>

### 题目：<u>____"AI灵宠"虚拟桌宠开发_____</u></font>
<br>

<font face="宋体"><font size="5"><b> 
班&nbsp;&nbsp;级&nbsp;2024219105 2024219104
姓&nbsp;&nbsp;名&nbsp;&nbsp;乐长昕&nbsp;&nbsp;&nbsp;罗添元&nbsp;
学&nbsp;&nbsp;号&nbsp;2023212455 2023212823

指导教师&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;吴晓非&nbsp;&nbsp;&nbsp;&nbsp;
</font></font>
<font face="Times New Roman"><font size="5">2025 年 9 月</font></font>	
<br><br>
*** 
<br>


</center>

## 1、任务概述

### 1.1、目标
**背景说明：**
当前现有的桌面应用功能趋于割裂：具备交互对话功能的桌宠功能单一、缺乏辅助功能和拓展能力，而拥有实用辅助功能的工具又缺乏生动的交互形式。本项目旨在突破这一局限，将智能桌面伴侣应用与实用型辅助功能有机融合，打造一个同时具备交互自然、辅助用户、功能可扩展的AI虚拟伙伴。
**产品与系统关系：**
可以运行在Microsoft Windows 10/11下，显示在用户桌面（浏览器/桌面壳）上层并允许用户通过操作交互，同时自动识别当前活跃软件并提供相关辅助功能，例如快捷键提示功能。覆盖层界面仅在需要时显示，不影响正常操作。
**主要应用目标：**
开发一款可长期常驻在用户桌面（浏览器/桌面壳）的**虚拟桌宠（AI Virtual Mate）**，目标体验包括：
- 视觉上具备**生动可爱的外观与流畅动画表现**（≥30fps），同时保持低系统资源占用
- 交互上实现**自然直观的交互体验**，支持点击、拖拽、喂食、表情互动、对话等多种互动方式
- 功能上可扩展，构建**可扩展的功能架构**，支持后续加载新角色、动作包及外部插件（如提醒、日程管理等）
- 智能上可选，**提供智能化能力选项**，支持接入云端或本地AI，实现对话交互与情绪识别等进阶功能（规划于后期实现）
### 1.2、系统特点
**目标用户特点：**
涵盖学生、上班族及二次元/轻松陪伴爱好者，致力于提供轻松、愉悦的桌面陪伴体验。
**产品特点：**
**开放且多样的AI生态：** 兼容多种云端与本地大语言模型、多模态模型及语音合成模型，支持DeepSeek-R1推理模型、Janus-Pro多模态模型等，并与OpenAI标准API无缝对接
**实时拟真语音交互：** 通过SenseVoice本地ASR引擎实现即时语音识别与交流，语音合成功能支持动态打断，用户可通过语音、按钮或快捷键中断过长回复
**多模态图像理解：** 支持屏幕捕获、摄像头输入及手动上传图片的多模态识别能力，增强虚拟伙伴的感知能力
**本地知识增强：** 可对接本地AnythingLLM或Dify聊天助手，提高虚拟伙伴对用户意图的理解和响应精度
**跨设备全平台访问**：在Windows端运行后，局域网内的其他设备（电脑、手机、平板、车机）均可通过浏览器访问虚拟伙伴。
**长期记忆功能：** 可选用Letta长期记忆框架，通过分层内存管理在不同会话和任务间保持状态，突破传统LLM无状态的限制
**高度自定义：** 用户可自由设置虚拟伙伴的名称、语音、人设、Live2D/MMD 3D角色模型，并个性化配置ASR、TTS、LLM、VLM等模块，实现真正的个性化体验
### 1.3、假定和约束
**假定：**
- 用户使用的软件为市场主流产品，能够被正常识别
- 用户设备具备基本的图形处理能力和网络连接
- 用户愿意授权应用监控当前活跃窗口信息

**约束：**
- 开发周期：约16周
- 支持Windows主流版本
- 隐私保护：不应收集敏感用户数据
- 性能要求：CPU占用率不超过5%，内存占用不超过200MB
- 浏览器环境支持：Chrome/Edge/Firefox（现代版本），支持 Canvas 或 WebGL
- 资源与版权：动画和音效尽量采用自制或开源许可证（MIT/CC0/CC-BY）；第三方素材须校验授权
- 运行性能：在常见笔记本（8GB RAM）上稳定运行；最长单资源加载延迟小于2s（采用懒加载/预加载策略）
## 2、需求规定
### 2.1、软件功能说明
#### 2.1.1、智能聊天功能
**输入**：用户文本/语音输入
**处理**：基于预设的虚拟伙伴的人设和性格、对话历史和选定的大语言模型进行自然语言理解、意图识别、生成回答，支持打断回复，语音支持词汇预设
**输出**：文本回复、语音播报、2/3D角色表情动作、指令执行
#### 2.1.2、图像理解功能
**输入**：含"看到/看见/照片/摄像头/屏幕/画面/图像"等词汇的指令或用户上传图片
**处理**：使用摄像头画面或屏幕截图，默认在使用云端GLM-4V模型处理，可切换本地模型
**输出**：内容转述、语音播报及其他互动
#### 2.1.3、 快捷键触发的提示及其他功能
**输入**：当前活跃窗口信息、用户预设配置、用户自定义快捷键
**处理**：窗口标题分析、软件识别、快捷键映射匹配
**输出**：覆盖层界面显示相关快捷键列表信息等
### 2.2、对功能的一般性规定
- 风格统一的图形界面与声音音效风格
- 格式统一的错误提示
- 详细的操作指引，如修改需要重启生效的设置时出现明确提示
### 2.3、用户界面
#### 图形界面
**主聊天界面**：对话气泡 + 角色显示区域
**设置面板**：模型选择、语音设置、图像识别设置的等分页显示
**功能按钮**：语音开关、图片上传、设置按钮等
#### 提示界面
- 软件状态视觉反馈（录音中、识别中、播放中）
- 加载进度显示
- 上传预览等功能
### 2.4、对性能的一般性规定
<b><u>（主要决定于所选模型性能）</b></u>

#### 2.4.1、精度要求
- 语音识别准确率 > 90%（安静环境）
- 唤醒词识别准确率 > 95%
- 图像识别基本物体识别准确率 > 85%
#### 2.4.2、时间特性要求
- 语音识别延迟 < 1秒
- 语言模型响应时间 < 3秒
- 语音合成延迟 < 2秒
- 图像识别处理时间 < 5秒
#### 2.4.3、灵活性
- 支持多种API标准（OpenAI兼容格式）
- 支持地和云端模型热切换，无需重启程序
#### 2.4.4、输入输出要求
**输入**：文本（2000字符内）、语音（16kHz）、图片（PNG格式）
**输出**：文本回复、合成语音、角色动画反馈
### 2.5、数据管理能力要求
- 对话记录存储：最近1000条对话
- 用户配置存储：< 5GB
- 可清理的本地缓存：< 500MB
### 2.6、故障处理要求
- 网络异常：自动切换到本地可用模型
- 模型加载失败：提示用户重新下载或选择其他模型
- 语音识别失败：提供文本输入备选方案
- 图像识别超时：提示用户重试或减小图片尺寸
### 2.7、其他专门要求 （易用性）
- 友好的操作指引与重点功能引导
- 在鼠标悬停时显示设置选项的简要功能说明
- 显示当前使用的模型和服务状态
## 3、运行环境规定
### 3.1、设备要求
- 操作系统：Windows 10或更高版本
- 处理器：Intel Core i5 8th / AMD R5 3000 系列或更高
- 内存：8GB RAM
- 显卡：Intel UHD 620 核显 / AMD Vega 7 核显
- 存储空间：至少2GB可用空间
- 网络：支持联网使用，也支持下载本地AI引擎DLC离线使用
- 麦克风：0.5米拾音（语音输入需求）
- 摄像头：720P彩色（多模态图像识别需求）
### 3.2、支撑软件
- Python 3.8+（本地模型运行）
- Ollama、AnythingLLM等本地服务
- 操作系统：Windows 10+/Linux/macOS
- 浏览器：Chrome/Edge/Firefox 最新版本
- 框架：Vue/React 前端框架；可选 Three.js（3D 动画）；后端 Node.js
### 3.3、接口规范
- 本地存储接口（保存设置）
- AI 对话接口（可接入 OpenAI API、Baidu 文心一言等）。
- 文件导入导出接口（配置、动作资源）
### 3.4、控制方式
**启动软件：** 双击运行程序，软件主界面将自动弹出AI虚拟伙伴对话网页
**桌面端操作：** 软件默认关闭实时语音交互，可使用快捷键切换实时语音开关。用户也可以在输入框内输入文本与虚拟伙伴进行对话。
**网页端操作：** 通过浏览器访问对话网页，输入用户名和密码登录后即可与虚拟伙伴进行交流。支持导出聊天记录和开启新对话。（Web端在非本电脑的其他设备上默认情况下仅支持打字聊天和显示角色，不支持语音识别、语音输出和摄像头识别）
## 4、尚需解决的问题
- 不同语音合成引擎的音频格式统一处理
- 本地模型内存占用与性能平衡优化
- 多模态识别中的上下文关联处理
- 图像识别指令的自然语言理解准确性
## 5、团队成员贡献率
- 乐长昕（50%）
- 罗添元（50%）